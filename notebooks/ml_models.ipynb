{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big G Express - Data Exploration\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = pd.read_pickle('../data/faults_filtered.pkl')\n",
    "# y_derate = pd.read_pickle('../data/target_derate.pkl') # this one is the base model, 6 hr\n",
    "#y_derate = pd.read_pickle('../data/target_derate3h.pkl')\n",
    "#y_derate = pd.read_pickle('../data/target_derate12h.pkl')\n",
    "y_derate = pd.read_pickle('../data/target_derate24h.pkl')\n",
    "#y_derate = pd.read_pickle('../data/target_derate6h_noderaterow.pkl')\n",
    "#y_75derate = pd.read_pickle('../data/target_75derate.pkl')\n",
    "diagnostics_imputed = pd.read_pickle('../data/diagnostics_imputed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is mostly NaNs, just 250 values or so\n",
    "diagnostics_imputed = diagnostics_imputed.drop(columns='ServiceDistance')\n",
    "\n",
    "# and this drops columns that are not useful for predictions\n",
    "faults = faults.drop(columns=['ESS_Id', 'active', 'eventDescription','ecuSoftwareVersion', 'ecuSerialNumber', \n",
    "    'ecuModel', 'ecuMake', 'ecuSource', 'MCTNumber', 'Latitude', 'Longitude', 'LocationTimeStamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember there are parts of columns (where a particular truck had no values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just a simple fill with mean..\n",
    "diagnostics_imputed['AcceleratorPedal'] = diagnostics_imputed['AcceleratorPedal'].fillna(value=diagnostics_imputed['AcceleratorPedal'].mean())\n",
    "diagnostics_imputed['CruiseControlSetSpeed'] = diagnostics_imputed['CruiseControlSetSpeed'].fillna(value=diagnostics_imputed['CruiseControlSetSpeed'].mean())\n",
    "diagnostics_imputed['EngineTimeLtd'] = diagnostics_imputed['EngineTimeLtd'].fillna(value=diagnostics_imputed['EngineTimeLtd'].mean())\n",
    "diagnostics_imputed['FuelLevel'] = diagnostics_imputed['FuelLevel'].fillna(value=diagnostics_imputed['FuelLevel'].mean())\n",
    "diagnostics_imputed['FuelTemperature'] = diagnostics_imputed['FuelTemperature'].fillna(value=diagnostics_imputed['FuelTemperature'].mean())\n",
    "diagnostics_imputed['SwitchedBatteryVoltage'] = diagnostics_imputed['SwitchedBatteryVoltage'].fillna(value=diagnostics_imputed['SwitchedBatteryVoltage'].mean())\n",
    "diagnostics_imputed['Throttle'] = diagnostics_imputed['Throttle'].fillna(value=diagnostics_imputed['Throttle'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this took 30 min and didn't stop ...\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer, KNNImputer\n",
    "# scaler = StandardScaler().fit(diagnostics_imputed)\n",
    "\n",
    "# knn_filled = scaler.inverse_transform(KNNImputer().fit_transform(scaler.transform(diagnostics_imputed)))\n",
    "\n",
    "# diagnostics_imputed = IterativeImputer().fit_transform(diagnostics_imputed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics['spn_fmi'] = ['_'.join(i) for i in zip(faults_diagnostics['spn'].astype(str), faults_diagnostics['fmi'].astype(str))]\n",
    "\n",
    "faults_diagnostics = pd.get_dummies(faults_diagnostics, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "faults_diagnostics = faults_diagnostics.sort_values(by=['EquipmentID', 'EventTimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain the one hot encoded columns since there are so many\n",
    "faults_cols = ['EventTimeStamp'] + [col for col in faults_diagnostics.columns if 'spn_fmi' in col] \n",
    "\n",
    "diagnostics_cols = ['EventTimeStamp', 'activeTransitionCount', 'AcceleratorPedal',\n",
    "         'BarometricPressure', 'CruiseControlSetSpeed', 'DistanceLtd',\n",
    "         'EngineCoolantTemperature', 'EngineLoad', 'EngineOilPressure', \n",
    "        'EngineOilTemperature', 'EngineRpm', 'EngineTimeLtd', 'FuelLevel', 'FuelLtd', \n",
    "        'FuelRate', 'FuelTemperature', 'IntakeManifoldTemperature', 'LampStatus',\n",
    "        'Speed', 'SwitchedBatteryVoltage', 'Throttle', 'TurboBoostPressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_rolling = (\n",
    "    faults_diagnostics\n",
    "    .groupby('EquipmentID')[faults_cols]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .max()\n",
    ")\n",
    "\n",
    "faults_rolling = faults_rolling.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics_rolling = (\n",
    "    faults_diagnostics\n",
    "    .groupby('EquipmentID')[diagnostics_cols]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "diagnostics_rolling = diagnostics_rolling.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_rolling = pd.merge(faults_diagnostics['RecordID'], #[['RecordID'] + diagnostics_cols]\n",
    "                          faults_rolling,\n",
    "                          left_index= True,\n",
    "                          right_on = 'level_1').drop(columns='level_1')\n",
    "\n",
    "diagnostics_rolling = pd.merge(faults_diagnostics['RecordID'],\n",
    "                          diagnostics_rolling,\n",
    "                          left_index= True,\n",
    "                          right_on = 'level_1').drop(columns='level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics_rolling =  pd.merge(diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            on = 'RecordID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics_rolling = faults_diagnostics_rolling.sort_values('RecordID').drop(columns='RecordID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faults_diagnostics_rolling = faults_rolling.drop(columns=['RecordID', 'EquipmentID', 'EventTimeStamp_x', 'EventTimeStamp_y'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stratify on target (with derate) and split based on trucks\n",
    "X_train, X_test, y_train, y_test = train_test_split(faults_diagnostics_rolling, y_derate.sort_values('RecordID')['target'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, gbr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, gbr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances.sort_values('importance', ascending = False).head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: during one of the trainings there was a particular spn-fmi code that got to the top, with importance of 0.8! It was the 46262 code and after inspecting, despite appearing only once in the dataset, since there are many events happening in a smlal timeframe around it, it got picked up as important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_smoted = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True))#n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr_smoted.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = gbr_smoted.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, gbr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, gbr_smoted.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'variable': gbr_smoted.feature_names_in_,\n",
    "    'importance': gbr_smoted['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances.sort_values('importance', ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=gbr_smoted.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Train-Test split\n",
    "\n",
    "The above is a good start. However, there are trucks whose events end up mixed between both train and test split. Instead, we want to make sure that each individual truck only appears in one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(faults['EquipmentID'].nunique())\n",
    "print(faults.loc[faults['spn'] == 5246]['EquipmentID'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, get the two lists of trucks that had (or not) a full derate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trucks = faults['EquipmentID'].unique()\n",
    "derate_trucks = faults.loc[faults['spn'] == 5246]['EquipmentID'].unique()\n",
    "no_derate_trucks = all_trucks[np.isin(all_trucks, derate_trucks, invert=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, put those lists together, marking if a derate occured (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_df = pd.concat([\n",
    "            pd.DataFrame({'EquipmentID': derate_trucks, 'derate': 1}),\n",
    "            pd.DataFrame({'EquipmentID': no_derate_trucks, 'derate': 0}) \n",
    "            ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, use the train_test_split, by accounting for the proportion of 'derates' in both (using stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_train, trucks_test = train_test_split(trucks_df, stratify=trucks_df['derate'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just to verify that the proportions of trucks with and without derate in two samples are equal\n",
    "# print(trucks_train['derate'].value_counts(normalize=True))\n",
    "# print(trucks_test['derate'].value_counts(normalize=True))\n",
    "\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])].shape[0])\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use that information to split the diagnostics and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to extract this because the train dataset only has RecordID\n",
    "records_train = faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])]['RecordID']\n",
    "records_test = faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])]['RecordID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_derate.loc[y_derate['RecordID'].isin(records_train)].sort_values('RecordID').drop(columns='RecordID')['target']\n",
    "y_test = y_derate.loc[y_derate['RecordID'].isin(records_test)].sort_values('RecordID').drop(columns='RecordID')['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the y_train and y_test are sorted, time to do the same for the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner').drop(columns='FaultId')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it depends on how these get prepared, so I'll build a function. It takes the faults + diagnostic con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowize_predictors(fulldetail_faults, time_window='1d', faults_agg='max', windowize_diagnostics = True, diagnostics_agg='mean'):\n",
    "\n",
    "    # pull out the diagnostics table columns for later\n",
    "    diagnostics_cols = [col for col in fulldetail_faults.columns if col not in ['RecordID', 'spn', 'fmi', 'EquipmentID']]\n",
    "\n",
    "    # create a combined spn_fmi column to make dummies out of\n",
    "    fulldetail_faults['spn_fmi'] = ['_'.join(i) for i in zip(fulldetail_faults['spn'].astype(str), fulldetail_faults['fmi'].astype(str))]\n",
    "\n",
    "    # make dummies (one hot encode)\n",
    "    fulldetail_faults = pd.get_dummies(fulldetail_faults, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "    # make sure the dataframe is in the right order to be able to later re-assign RecordID to it\n",
    "    fulldetail_faults = fulldetail_faults.sort_values(by=['EquipmentID', 'EventTimeStamp'])\n",
    "\n",
    "    # pull out all the Faults table columns (now one hot encoded)\n",
    "    faults_cols = ['EventTimeStamp'] + [col for col in fulldetail_faults.columns if 'spn_fmi' in col] \n",
    "\n",
    "    # rolling window function over faults - by default just taking IF a code appears in a 24 hr past window\n",
    "    faults_rolling = (\n",
    "        fulldetail_faults\n",
    "            .groupby('EquipmentID')[faults_cols]\n",
    "            .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "            .agg(faults_agg)\n",
    "            .reset_index()\n",
    "    )\n",
    "    \n",
    "    # by default I also decided to apply the same rolling window for the diagnostics part\n",
    "    # (can be turned off by setting = False, it is quick to execute)\n",
    "    if windowize_diagnostics:\n",
    "\n",
    "        # rolling window over diagnostics, by default using mean\n",
    "        diagnostics_rolling = (\n",
    "            fulldetail_faults\n",
    "                .groupby('EquipmentID')[diagnostics_cols]\n",
    "                .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "                .agg(diagnostics_agg)\n",
    "                .reset_index()\n",
    "        )\n",
    "\n",
    "        # joining back the faults rw to the original dataframe to get the \"RecordID\" out\n",
    "        faults_rolling = pd.merge(fulldetail_faults[['RecordID', 'spn']],\n",
    "                            faults_rolling,\n",
    "                            left_index= True,\n",
    "                            right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        ###### ONLY uncomment this next line IF the derate rows are not tagged\n",
    "        # faults_rolling = faults_rolling.loc[faults_rolling['spn'] != 5246]\n",
    "\n",
    "        # joining back the diagnostics rw to the original dataframe to get the \"RecordID\" out\n",
    "        diagnostics_rolling = pd.merge(fulldetail_faults[['RecordID', 'spn']],\n",
    "                                diagnostics_rolling,\n",
    "                                left_index= True,\n",
    "                                right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        ####### ONLY uncomment this next line IF the derate rows are not tagged\n",
    "        # diagnostics_rolling = diagnostics_rolling.loc[diagnostics_rolling['spn'] != 5246]\n",
    "        \n",
    "        # joining the two rolling windows\n",
    "        faults_diagnostics_rolling =  pd.merge(\n",
    "            diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp', 'spn']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp', 'spn']),\n",
    "            on = 'RecordID'\n",
    "        )\n",
    "\n",
    "    # this gets used if we only want to take into account the current diagnostics\n",
    "    # (essentially, NO rolling window for diagnostics)\n",
    "    else :\n",
    "\n",
    "        # simply get back 'RecordID' and other diagnostic columns\n",
    "        faults_diagnostics_rolling = pd.merge(\n",
    "            fulldetail_faults[['RecordID', 'spn'] + diagnostics_cols].drop(columns=['EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            left_index= True,\n",
    "            right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        ####### ONLY uncomment this next line IF the derate rows are not tagged\n",
    "        # faults_diagnostics_rolling = faults_diagnostics_rolling.loc[faults_diagnostics_rolling['spn'] != 5246]\n",
    "        \n",
    "        faults_diagnostics_rolling = faults_diagnostics_rolling.drop(columns='spn')\n",
    "        \n",
    "    predictor_train = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_train)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "    predictor_test = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_test)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "\n",
    "    return predictor_train, predictor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = windowize_predictors(faults_diagnostics, time_window='7d', faults_agg='max', windowize_diagnostics=False, diagnostics_agg='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0523            7.19m\n",
      "         2           0.0484            7.07m\n",
      "         3           0.0507            6.94m\n",
      "         4        2410.8273            6.79m\n",
      "         5        2410.8265            6.74m\n",
      "         6        2410.8259            6.67m\n",
      "         7        2410.8254            6.60m\n",
      "         8        2410.8251            6.56m\n",
      "         9        2410.8248            6.49m\n",
      "        10        2410.8245            6.42m\n",
      "        20        2410.8182            5.71m\n",
      "        30        2410.8150            5.00m\n",
      "        40        2410.8130            4.29m\n",
      "        50        2410.8120            3.57m\n",
      "        60        2410.8112            2.86m\n",
      "        70        2410.8106            2.14m\n",
      "        80        2410.8101            1.43m\n",
      "        90        2410.8113           42.90s\n",
      "       100        2410.8107            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[440508    307]\n",
      " [  1118    868]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    440815\n",
      "           1       0.74      0.44      0.55      1986\n",
      "\n",
      "    accuracy                           1.00    442801\n",
      "   macro avg       0.87      0.72      0.77    442801\n",
      "weighted avg       1.00      1.00      1.00    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>spn_fmi_74_14</td>\n",
       "      <td>0.381216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.097102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EngineTimeLtd</td>\n",
       "      <td>0.090937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>spn_fmi_5246_0</td>\n",
       "      <td>0.076297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>spn_fmi_5848_9</td>\n",
       "      <td>0.074982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>spn_fmi_524287_31</td>\n",
       "      <td>0.074748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistanceLtd</td>\n",
       "      <td>0.036382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>spn_fmi_5246_19</td>\n",
       "      <td>0.035623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>spn_fmi_3226_9</td>\n",
       "      <td>0.031183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>spn_fmi_5394_17</td>\n",
       "      <td>0.015174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>spn_fmi_5246_15</td>\n",
       "      <td>0.008241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EngineOilTemperature</td>\n",
       "      <td>0.007595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EngineRpm</td>\n",
       "      <td>0.007196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>spn_fmi_1569_31</td>\n",
       "      <td>0.006264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FuelLtd</td>\n",
       "      <td>0.005999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>spn_fmi_5246_16</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>spn_fmi_5113_9</td>\n",
       "      <td>0.003871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>spn_fmi_5394_4</td>\n",
       "      <td>0.003662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SwitchedBatteryVoltage</td>\n",
       "      <td>0.003315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>spn_fmi_3364_9</td>\n",
       "      <td>0.003021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   variable  importance\n",
       "840           spn_fmi_74_14    0.381216\n",
       "16               LampStatus    0.097102\n",
       "10            EngineTimeLtd    0.090937\n",
       "624          spn_fmi_5246_0    0.076297\n",
       "717          spn_fmi_5848_9    0.074982\n",
       "622       spn_fmi_524287_31    0.074748\n",
       "4               DistanceLtd    0.036382\n",
       "628         spn_fmi_5246_19    0.035623\n",
       "343          spn_fmi_3226_9    0.031183\n",
       "638         spn_fmi_5394_17    0.015174\n",
       "626         spn_fmi_5246_15    0.008241\n",
       "8      EngineOilTemperature    0.007595\n",
       "9                 EngineRpm    0.007196\n",
       "163         spn_fmi_1569_31    0.006264\n",
       "12                  FuelLtd    0.005999\n",
       "627         spn_fmi_5246_16    0.005897\n",
       "592          spn_fmi_5113_9    0.003871\n",
       "640          spn_fmi_5394_4    0.003662\n",
       "18   SwitchedBatteryVoltage    0.003315\n",
       "400          spn_fmi_3364_9    0.003021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "[[103334     91]\n",
      " [   332    116]]\n",
      "ROC AUC Score\n",
      "0.9493531264028453\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)\n",
    "\n",
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2467           20.95m\n",
      "         2           1.1325           20.47m\n",
      "         3           1.0370           20.58m\n",
      "         4           0.9576           20.58m\n",
      "         5           0.8902           21.29m\n",
      "         6           0.8325           21.14m\n",
      "         7           0.7827           21.09m\n",
      "         8           0.7391           20.91m\n",
      "         9           0.7021           20.60m\n",
      "        10           0.6696           20.18m\n",
      "        20           0.4625           18.56m\n",
      "        30           0.3744           16.10m\n",
      "        40           0.3264           13.84m\n",
      "        50           0.2955           11.00m\n",
      "        60           0.2721            8.39m\n",
      "        70           0.2553            6.06m\n",
      "        80           0.2406            3.93m\n",
      "        90           0.2273            1.92m\n",
      "       100           0.2185            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is going to re-fit from scratch, unless we set warm_start=True\n",
    "# also, simply add this line to all X_ variables if you want to exclude 5246 influencing the model:\n",
    "# .drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col])\n",
    "gbr.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[426454  14361]\n",
      " [   186   1800]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    440815\n",
      "           1       0.11      0.91      0.20      1986\n",
      "\n",
      "    accuracy                           0.97    442801\n",
      "   macro avg       0.56      0.94      0.59    442801\n",
      "weighted avg       1.00      0.97      0.98    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>spn_fmi_1569_31</td>\n",
       "      <td>0.438912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FuelTemperature</td>\n",
       "      <td>0.234057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.074303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activeTransitionCount</td>\n",
       "      <td>0.038777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>spn_fmi_3031_9</td>\n",
       "      <td>0.035722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>spn_fmi_5848_9</td>\n",
       "      <td>0.017069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>spn_fmi_3226_9</td>\n",
       "      <td>0.011243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>spn_fmi_5246_16</td>\n",
       "      <td>0.009862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>spn_fmi_3362_31</td>\n",
       "      <td>0.009312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CruiseControlSetSpeed</td>\n",
       "      <td>0.009020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EngineTimeLtd</td>\n",
       "      <td>0.008366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>spn_fmi_3364_9</td>\n",
       "      <td>0.008076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>spn_fmi_5743_9</td>\n",
       "      <td>0.006681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>spn_fmi_5246_15</td>\n",
       "      <td>0.005374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>spn_fmi_792_14</td>\n",
       "      <td>0.005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>spn_fmi_1787_11</td>\n",
       "      <td>0.004752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>spn_fmi_111_17</td>\n",
       "      <td>0.004719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FuelLtd</td>\n",
       "      <td>0.004199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>spn_fmi_4094_31</td>\n",
       "      <td>0.003757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>spn_fmi_1209_2</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable  importance\n",
       "163        spn_fmi_1569_31    0.438912\n",
       "14         FuelTemperature    0.234057\n",
       "16              LampStatus    0.074303\n",
       "0    activeTransitionCount    0.038777\n",
       "300         spn_fmi_3031_9    0.035722\n",
       "717         spn_fmi_5848_9    0.017069\n",
       "343         spn_fmi_3226_9    0.011243\n",
       "627        spn_fmi_5246_16    0.009862\n",
       "389        spn_fmi_3362_31    0.009312\n",
       "3    CruiseControlSetSpeed    0.009020\n",
       "10           EngineTimeLtd    0.008366\n",
       "400         spn_fmi_3364_9    0.008076\n",
       "699         spn_fmi_5743_9    0.006681\n",
       "626        spn_fmi_5246_15    0.005374\n",
       "892         spn_fmi_792_14    0.005018\n",
       "219        spn_fmi_1787_11    0.004752\n",
       "90          spn_fmi_111_17    0.004719\n",
       "12                 FuelLtd    0.004199\n",
       "468        spn_fmi_4094_31    0.003757\n",
       "109         spn_fmi_1209_2    0.003755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "confusion matrix\n",
      "[[100254   3171]\n",
      " [    69    379]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    103425\n",
      "           1       0.11      0.85      0.19       448\n",
      "\n",
      "    accuracy                           0.97    103873\n",
      "   macro avg       0.55      0.91      0.59    103873\n",
      "weighted avg       1.00      0.97      0.98    103873\n",
      "\n",
      "ROC AUC Score\n",
      "0.960453755740875\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('classification report')\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gbr_model_17.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load model\n",
    "# gbr = load('../models/gbr_model_1.joblib') \n",
    "\n",
    "# to save model\n",
    "#dump(gbr, '../models/gbr_model_17.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides saving the models, I will construct a json file that describes how they were obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dump = {\n",
    "    'file_path' : '../models/gbr_model_17.joblib',\n",
    "    'targets' : 'any row where a derate (5246) happens in the next 24 hours',\n",
    "    'diagnostics_file' : 'used imputer to average data per truck and then simple mean to average any remaining nulls',\n",
    "    'train_test_split' : 'using trucks and assuring same ratio of derate and nonderate',\n",
    "    'windowize_predictors': {'dataframe': 'merged faults and diagnostics',\n",
    "                             'how far in the past to aggregate' : '7 days',\n",
    "                             'how to aggregate the one-hot encoded spn_fmi': 'max (default)',\n",
    "                             'use rolling window on diagnostics?' : 'False ',\n",
    "                             'how to aggregate diagnostics data' : 'mean'},\n",
    "    'pipeline' : {'step 1': 'GradientBoostingClassifier (default values)'},\n",
    "    'rebalancing' : {'over or under fitting': 'used SMOTE(k_neighbors=5, random_state=42)',\n",
    "                     'variables used': 'all (including derate columns)'}\n",
    "\n",
    "}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_train, gbr.predict(X_train))\n",
    "\n",
    "to_dump['train_confusion_matrix'] = {'TN': int(tmp_matrix[0][0]),\n",
    "                                     'FP': int(tmp_matrix[0][1]),\n",
    "                                     'FN': int(tmp_matrix[1][0]),\n",
    "                                     'TP': int(tmp_matrix[1][1])}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_test, gbr.predict(X_test))\n",
    "\n",
    "to_dump['test_confusion_matrix'] = {'TN': int(tmp_matrix[0][0]),\n",
    "                                    'FP': int(tmp_matrix[0][1]),\n",
    "                                    'FN': int(tmp_matrix[1][0]),\n",
    "                                    'TP': int(tmp_matrix[1][1])}\n",
    "\n",
    "\n",
    "to_dump['test_rocaouc_score'] = roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances = importances.sort_values('importance', ascending = False).head(20)\n",
    "\n",
    "tmp_dict={}\n",
    "\n",
    "for index, row in importances.iterrows():\n",
    "    tmp_dict[row[\"variable\"]] = row['importance']\n",
    "\n",
    "to_dump['top20_fature_importances'] = tmp_dict\n",
    "\n",
    "\n",
    "json_object = json.dumps(to_dump, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/gbr_model_17.json', 'w') as outfile:\n",
    "#     outfile.write(json_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into the most promising model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First few steps are straightforward as outlined below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael's suggestion was to check if any of the false positives actually happen to have a derate within 24 hours. Adding that to the dataframe from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model that I want to use to look at the predictions\n",
    "gbr_best = load('../models/gbr_model_11.joblib')\n",
    "\n",
    "# get the target values \n",
    "# note: the model might have been trained on a different time window, but if it correctly predicts derates further down the road, that is perfectly fine\n",
    "# that is why, using Michael's suggestion, always compare models to the 24 hr derate window\n",
    "y_derate = pd.read_pickle('../data/target_derate24h.pkl')\n",
    "\n",
    "y_comparison = y_derate.loc[y_derate['RecordID'].isin(records_test)].sort_values('RecordID')\n",
    "\n",
    "# preditc y values based on model\n",
    "y_pred = gbr_best.predict(X_test) #.drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col])\n",
    "\n",
    "# put all of it together in a dataframe\n",
    "y_comparison['predicted'] = y_pred\n",
    "\n",
    "# merge it back to get the complete faults info\n",
    "test_results = pd.merge(faults, y_comparison, on='RecordID', how='inner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the confusion Matrix for the model 5:\n",
    "- \"TN\": 100535\n",
    "- \"FP\": 3099\n",
    "- \"FN\": 37\n",
    "- \"TP\": 202\n",
    "\n",
    "This is the confusion Matrix for the model 16:\n",
    "- \"TN\": 99488\n",
    "- \"FP\": 3937\n",
    "- \"FN\": 66\n",
    "- \"TP\": 382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>spn</th>\n",
       "      <th>fmi</th>\n",
       "      <th>activeTransitionCount</th>\n",
       "      <th>EquipmentID</th>\n",
       "      <th>target</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-02-21 11:35:33</td>\n",
       "      <td>1807</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2015-02-21 11:40:22</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2015-02-21 11:14:38</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>2015-02-21 12:01:10</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>2015-02-21 12:13:47</td>\n",
       "      <td>1807</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>1369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103868</th>\n",
       "      <td>1248425</td>\n",
       "      <td>2020-03-06 12:00:41</td>\n",
       "      <td>829</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>1853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103869</th>\n",
       "      <td>1248426</td>\n",
       "      <td>2020-03-06 12:00:41</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>1853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103870</th>\n",
       "      <td>1248431</td>\n",
       "      <td>2020-03-06 12:20:36</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>1853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103871</th>\n",
       "      <td>1248432</td>\n",
       "      <td>2020-03-06 12:20:36</td>\n",
       "      <td>829</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>1853</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103872</th>\n",
       "      <td>1248452</td>\n",
       "      <td>2020-03-06 13:42:48</td>\n",
       "      <td>111</td>\n",
       "      <td>18</td>\n",
       "      <td>93</td>\n",
       "      <td>1886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103873 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RecordID      EventTimeStamp   spn  fmi  activeTransitionCount  \\\n",
       "0              4 2015-02-21 11:35:33  1807    2                    127   \n",
       "1              6 2015-02-21 11:40:22   111   17                      1   \n",
       "2             15 2015-02-21 11:14:38  1067    2                    127   \n",
       "3             35 2015-02-21 12:01:10   111   17                      1   \n",
       "4             50 2015-02-21 12:13:47  1807    2                    127   \n",
       "...          ...                 ...   ...  ...                    ...   \n",
       "103868   1248425 2020-03-06 12:00:41   829    3                    126   \n",
       "103869   1248426 2020-03-06 12:00:41    96    3                    126   \n",
       "103870   1248431 2020-03-06 12:20:36    96    3                    126   \n",
       "103871   1248432 2020-03-06 12:20:36   829    3                    126   \n",
       "103872   1248452 2020-03-06 13:42:48   111   18                     93   \n",
       "\n",
       "       EquipmentID  target  predicted  \n",
       "0             1369       0          0  \n",
       "1             1417       0          0  \n",
       "2              309       0          0  \n",
       "3             1585       0          0  \n",
       "4             1369       0          0  \n",
       "...            ...     ...        ...  \n",
       "103868        1853       0          0  \n",
       "103869        1853       0          0  \n",
       "103870        1853       0          0  \n",
       "103871        1853       0          0  \n",
       "103872        1886       0          0  \n",
       "\n",
       "[103873 rows x 8 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the false positives\n",
    "false_positive = test_results.loc[(test_results['target'] == 0) & (test_results['predicted'] == 1)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic here is that if I use the rolling window again, I can sum up on the \"predicted\" values. Any sums that are more than 1 indicate repeated values. I.e. they show that those predictions occur within 24 hours and therefore, they were not actually separate predictions of the model.\n",
    "\n",
    "In order to get the unique false predictions, we count how many times 'predicted' was 1.\n",
    "\n",
    "**results**:\n",
    "- model 5: 819 out of 3099 are false positives\n",
    "- model 16: 709 out of 3937 are false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EquipmentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <th>635</th>\n",
       "      <td>2015-02-25 15:38:07</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <th>7575</th>\n",
       "      <td>2015-06-12 16:25:19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1343</th>\n",
       "      <th>2593</th>\n",
       "      <td>2015-04-23 18:13:33</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>2015-04-27 16:18:02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>2015-04-28 23:35:13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <th>87711</th>\n",
       "      <td>2018-04-29 16:20:09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <th>102837</th>\n",
       "      <td>2020-01-16 13:35:15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <th>102946</th>\n",
       "      <td>2020-01-20 12:46:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">309</th>\n",
       "      <th>86386</th>\n",
       "      <td>2018-03-12 11:31:45</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86574</th>\n",
       "      <td>2018-03-16 05:43:56</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        EventTimeStamp  predicted\n",
       "EquipmentID                                      \n",
       "1329        635    2015-02-25 15:38:07        1.0\n",
       "1339        7575   2015-06-12 16:25:19        1.0\n",
       "1343        2593   2015-04-23 18:13:33        1.0\n",
       "            2899   2015-04-27 16:18:02        1.0\n",
       "            3060   2015-04-28 23:35:13        1.0\n",
       "...                                ...        ...\n",
       "2171        87711  2018-04-29 16:20:09        1.0\n",
       "2220        102837 2020-01-16 13:35:15        1.0\n",
       "2338        102946 2020-01-20 12:46:31        1.0\n",
       "309         86386  2018-03-12 11:31:45        1.0\n",
       "            86574  2018-03-16 05:43:56        1.0\n",
       "\n",
       "[835 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive = (\n",
    "    false_positive\n",
    "    .sort_values(['EquipmentID','EventTimeStamp'])\n",
    "    .groupby('EquipmentID')[['EventTimeStamp', 'predicted']]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "false_positive.loc[false_positive['predicted'] == 1.]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar approach to get the false negatives, except now we invert target and predicted.\n",
    "\n",
    "**results**:\n",
    "- model 5: 11 out of 37 are false negatives\n",
    "- model 16: 22 out of 66 are false negatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the false negatives\n",
    "false_negative = test_results.loc[(test_results['target'] == 1) & (test_results['predicted'] == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative = (\n",
    "    false_negative\n",
    "    .sort_values(['EquipmentID','EventTimeStamp'])\n",
    "    .groupby('EquipmentID')[['EventTimeStamp', 'target']]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "len(false_negative.loc[false_negative['target'] == 1.])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, looking at the true positives\n",
    "\n",
    "**results**: \n",
    "- 67 out of 202 are true positives, out of which 21 are predicted at least 2 hours in advance\n",
    "- 67 out of 382 are true positives, out of which 45 are predicted at least 2 hours in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the true positive\n",
    "true_positive = test_results.loc[(test_results['target'] == 1) & (test_results['predicted'] == 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = (\n",
    "    true_positive\n",
    "    .sort_values(['EquipmentID','EventTimeStamp'])\n",
    "    .groupby('EquipmentID')[['EventTimeStamp', 'RecordID', 'predicted', 'target']]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .agg({'RecordID': lambda x: x[-1], 'predicted': 'sum', 'target': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "true_positive['RecordID'] = true_positive['RecordID'].astype(int)\n",
    "\n",
    "true_positive = true_positive.loc[true_positive['predicted'] == 1.]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: do not use iterrows to modify the dataframe it's being iterated over!! the results are not guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EquipmentID</th>\n",
       "      <th>EventTimeStamp</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>predicted</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1329</td>\n",
       "      <td>2015-02-25 13:53:08</td>\n",
       "      <td>5713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1339</td>\n",
       "      <td>2015-06-12 08:24:15</td>\n",
       "      <td>85259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1366</td>\n",
       "      <td>2015-06-11 10:08:58</td>\n",
       "      <td>84237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1366</td>\n",
       "      <td>2015-07-03 15:10:45</td>\n",
       "      <td>109732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1366</td>\n",
       "      <td>2015-09-23 04:36:59</td>\n",
       "      <td>214072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>1919</td>\n",
       "      <td>2018-11-04 08:07:49</td>\n",
       "      <td>1075078</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1922</td>\n",
       "      <td>2019-07-07 11:13:03</td>\n",
       "      <td>1176722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1970</td>\n",
       "      <td>2019-04-28 17:50:36</td>\n",
       "      <td>1153464</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2004</td>\n",
       "      <td>2019-07-03 07:08:25</td>\n",
       "      <td>1176072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2009</td>\n",
       "      <td>2017-06-24 10:42:36</td>\n",
       "      <td>815232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    EquipmentID      EventTimeStamp  RecordID  predicted  target\n",
       "0          1329 2015-02-25 13:53:08      5713        1.0     1.0\n",
       "4          1339 2015-06-12 08:24:15     85259        1.0     1.0\n",
       "6          1366 2015-06-11 10:08:58     84237        1.0     1.0\n",
       "20         1366 2015-07-03 15:10:45    109732        1.0     1.0\n",
       "22         1366 2015-09-23 04:36:59    214072        1.0     1.0\n",
       "..          ...                 ...       ...        ...     ...\n",
       "335        1919 2018-11-04 08:07:49   1075078        1.0     1.0\n",
       "338        1922 2019-07-07 11:13:03   1176722        1.0     1.0\n",
       "353        1970 2019-04-28 17:50:36   1153464        1.0     1.0\n",
       "363        2004 2019-07-03 07:08:25   1176072        1.0     1.0\n",
       "364        2009 2017-06-24 10:42:36    815232        1.0     1.0\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "derate_times = []\n",
    "\n",
    "for index, row in true_positive.iterrows():\n",
    "    derate_times.append(\n",
    "        faults.loc[(faults['EquipmentID'] == str(row['EquipmentID']))\n",
    "                   & (faults['spn'] == 5246) \n",
    "                   & (faults['EventTimeStamp'] >= row['EventTimeStamp'])]\n",
    "                   .iloc[0]['EventTimeStamp']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive['derateTimeStamp'] = derate_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive['timediff'] = true_positive['derateTimeStamp'] - true_positive['EventTimeStamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_positive.loc[true_positive['timediff'] > timedelta(hours= 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
