{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big G Express - Data Exploration\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = pd.read_pickle('../data/faults_filtered.pkl')\n",
    "#y_derate = pd.read_pickle('../data/target_derate.pkl') # this one is the base model, 6 hr\n",
    "#y_derate = pd.read_pickle('../data/target_derate3h.pkl')\n",
    "#y_derate = pd.read_pickle('../data/target_derate12h.pkl')\n",
    "y_derate = pd.read_pickle('../data/target_derate24h.pkl')\n",
    "#y_75derate = pd.read_pickle('../data/target_75derate.pkl')\n",
    "diagnostics_imputed = pd.read_pickle('../data/diagnostics_imputed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is mostly NaNs, just 250 values or so\n",
    "diagnostics_imputed = diagnostics_imputed.drop(columns='ServiceDistance')\n",
    "\n",
    "# and this drops columns that are not useful for predictions\n",
    "faults = faults.drop(columns=['ESS_Id', 'active', 'eventDescription','ecuSoftwareVersion', 'ecuSerialNumber', \n",
    "    'ecuModel', 'ecuMake', 'ecuSource', 'MCTNumber', 'Latitude', 'Longitude', 'LocationTimeStamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember there are parts of columns (where a particular truck had no values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just a simple fill with mean..\n",
    "diagnostics_imputed['AcceleratorPedal'] = diagnostics_imputed['AcceleratorPedal'].fillna(value=diagnostics_imputed['AcceleratorPedal'].mean())\n",
    "diagnostics_imputed['CruiseControlSetSpeed'] = diagnostics_imputed['CruiseControlSetSpeed'].fillna(value=diagnostics_imputed['CruiseControlSetSpeed'].mean())\n",
    "diagnostics_imputed['EngineTimeLtd'] = diagnostics_imputed['EngineTimeLtd'].fillna(value=diagnostics_imputed['EngineTimeLtd'].mean())\n",
    "diagnostics_imputed['FuelLevel'] = diagnostics_imputed['FuelLevel'].fillna(value=diagnostics_imputed['FuelLevel'].mean())\n",
    "diagnostics_imputed['FuelTemperature'] = diagnostics_imputed['FuelTemperature'].fillna(value=diagnostics_imputed['FuelTemperature'].mean())\n",
    "diagnostics_imputed['SwitchedBatteryVoltage'] = diagnostics_imputed['SwitchedBatteryVoltage'].fillna(value=diagnostics_imputed['SwitchedBatteryVoltage'].mean())\n",
    "diagnostics_imputed['Throttle'] = diagnostics_imputed['Throttle'].fillna(value=diagnostics_imputed['Throttle'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this took 30 min and didn't stop ...\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer, KNNImputer\n",
    "# scaler = StandardScaler().fit(diagnostics_imputed)\n",
    "\n",
    "# knn_filled = scaler.inverse_transform(KNNImputer().fit_transform(scaler.transform(diagnostics_imputed)))\n",
    "\n",
    "# diagnostics_imputed = IterativeImputer().fit_transform(diagnostics_imputed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics['spn_fmi'] = ['_'.join(i) for i in zip(faults_diagnostics['spn'].astype(str), faults_diagnostics['fmi'].astype(str))]\n",
    "\n",
    "faults_diagnostics = pd.get_dummies(faults_diagnostics, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "faults_diagnostics = faults_diagnostics.sort_values(by=['EquipmentID', 'EventTimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain the one hot encoded columns since there are so many\n",
    "faults_cols = ['EventTimeStamp'] + [col for col in faults_diagnostics.columns if 'spn_fmi' in col] \n",
    "\n",
    "diagnostics_cols = ['EventTimeStamp', 'activeTransitionCount', 'AcceleratorPedal',\n",
    "         'BarometricPressure', 'CruiseControlSetSpeed', 'DistanceLtd',\n",
    "         'EngineCoolantTemperature', 'EngineLoad', 'EngineOilPressure', \n",
    "        'EngineOilTemperature', 'EngineRpm', 'EngineTimeLtd', 'FuelLevel', 'FuelLtd', \n",
    "        'FuelRate', 'FuelTemperature', 'IntakeManifoldTemperature', 'LampStatus',\n",
    "        'Speed', 'SwitchedBatteryVoltage', 'Throttle', 'TurboBoostPressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_rolling = (\n",
    "    faults_diagnostics\n",
    "    .groupby('EquipmentID')[faults_cols]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .max()\n",
    ")\n",
    "\n",
    "faults_rolling = faults_rolling.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics_rolling = (\n",
    "    faults_diagnostics\n",
    "    .groupby('EquipmentID')[diagnostics_cols]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "diagnostics_rolling = diagnostics_rolling.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_rolling = pd.merge(faults_diagnostics['RecordID'], #[['RecordID'] + diagnostics_cols]\n",
    "                          faults_rolling,\n",
    "                          left_index= True,\n",
    "                          right_on = 'level_1').drop(columns='level_1')\n",
    "\n",
    "diagnostics_rolling = pd.merge(faults_diagnostics['RecordID'],\n",
    "                          diagnostics_rolling,\n",
    "                          left_index= True,\n",
    "                          right_on = 'level_1').drop(columns='level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics_rolling =  pd.merge(diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            on = 'RecordID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics_rolling = faults_diagnostics_rolling.sort_values('RecordID').drop(columns='RecordID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faults_diagnostics_rolling = faults_rolling.drop(columns=['RecordID', 'EquipmentID', 'EventTimeStamp_x', 'EventTimeStamp_y'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stratify on target (with derate) and split based on trucks\n",
    "X_train, X_test, y_train, y_test = train_test_split(faults_diagnostics_rolling, y_derate.sort_values('RecordID')['target'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, gbr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, gbr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances.sort_values('importance', ascending = False).head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: during one of the trainings there was a particular spn-fmi code that got to the top, with importance of 0.8! It was the 46262 code and after inspecting, despite appearing only once in the dataset, since there are many events happening in a smlal timeframe around it, it got picked up as important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_smoted = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True))#n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr_smoted.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = gbr_smoted.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, gbr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, gbr_smoted.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'variable': gbr_smoted.feature_names_in_,\n",
    "    'importance': gbr_smoted['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances.sort_values('importance', ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=gbr_smoted.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Train-Test split\n",
    "\n",
    "The above is a good start. However, there are trucks whose events end up mixed between both train and test split. Instead, we want to make sure that each individual truck only appears in one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(faults['EquipmentID'].nunique())\n",
    "print(faults.loc[faults['spn'] == 5246]['EquipmentID'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, get the two lists of trucks that had (or not) a full derate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trucks = faults['EquipmentID'].unique()\n",
    "derate_trucks = faults.loc[faults['spn'] == 5246]['EquipmentID'].unique()\n",
    "no_derate_trucks = all_trucks[np.isin(all_trucks, derate_trucks, invert=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, put those lists together, marking if a derate occured (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_df = pd.concat([\n",
    "            pd.DataFrame({'EquipmentID': derate_trucks, 'derate': 1}),\n",
    "            pd.DataFrame({'EquipmentID': no_derate_trucks, 'derate': 0}) \n",
    "            ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, use the train_test_split, by accounting for the proportion of 'derates' in both (using stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_train, trucks_test = train_test_split(trucks_df, stratify=trucks_df['derate'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just to verify that the proportions of trucks with and without derate in two samples are equal\n",
    "# print(trucks_train['derate'].value_counts(normalize=True))\n",
    "# print(trucks_test['derate'].value_counts(normalize=True))\n",
    "\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])].shape[0])\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use that information to split the diagnostics and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to extract this because the train dataset only has RecordID\n",
    "records_train = faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])]['RecordID']\n",
    "records_test = faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])]['RecordID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_derate.loc[y_derate['RecordID'].isin(records_train)].sort_values('RecordID').drop(columns='RecordID')['target']\n",
    "y_test = y_derate.loc[y_derate['RecordID'].isin(records_test)].sort_values('RecordID').drop(columns='RecordID')['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the y_train and y_test are sorted, time to do the same for the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner').drop(columns='FaultId')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it depends on how these get prepared, so I'll build a function. It takes the faults + diagnostic con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowize_predictors(fulldetail_faults, time_window='1d', faults_agg='max', windowize_diagnostics = True, diagnostics_agg='mean'):\n",
    "\n",
    "    # pull out the diagnostics table columns for later\n",
    "    diagnostics_cols = [col for col in fulldetail_faults.columns if col not in ['RecordID', 'spn', 'fmi', 'EquipmentID']]\n",
    "\n",
    "    # create a combined spn_fmi column to make dummies out of\n",
    "    fulldetail_faults['spn_fmi'] = ['_'.join(i) for i in zip(fulldetail_faults['spn'].astype(str), fulldetail_faults['fmi'].astype(str))]\n",
    "\n",
    "    # make dummies (one hot encode)\n",
    "    fulldetail_faults = pd.get_dummies(fulldetail_faults, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "    # make sure the dataframe is in the right order to be able to later re-assign RecordID to it\n",
    "    fulldetail_faults = fulldetail_faults.sort_values(by=['EquipmentID', 'EventTimeStamp'])\n",
    "\n",
    "    # pull out all the Faults table columns (now one hot encoded)\n",
    "    faults_cols = ['EventTimeStamp'] + [col for col in fulldetail_faults.columns if 'spn_fmi' in col] \n",
    "\n",
    "    # rolling window function over faults - by default just taking IF a code appears in a 24 hr past window\n",
    "    faults_rolling = (\n",
    "        fulldetail_faults\n",
    "            .groupby('EquipmentID')[faults_cols]\n",
    "            .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "            .agg(faults_agg)\n",
    "            .reset_index()\n",
    "    )\n",
    "    \n",
    "    # by default I also decided to apply the same rolling window for the diagnostics part\n",
    "    # (can be turned off by setting = False, it is quick to execute)\n",
    "    if windowize_diagnostics:\n",
    "\n",
    "        # rolling window over diagnostics, by default using mean\n",
    "        diagnostics_rolling = (\n",
    "            fulldetail_faults\n",
    "                .groupby('EquipmentID')[diagnostics_cols]\n",
    "                .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "                .agg(diagnostics_agg)\n",
    "                .reset_index()\n",
    "        )\n",
    "\n",
    "        # joining back the faults rw to the original dataframe to get the \"RecordID\" out\n",
    "        faults_rolling = pd.merge(fulldetail_faults['RecordID'],\n",
    "                            faults_rolling,\n",
    "                            left_index= True,\n",
    "                            right_on = 'level_1').drop(columns='level_1')\n",
    "\n",
    "        # joining back the diagnostics rw to the original dataframe to get the \"RecordID\" out\n",
    "        diagnostics_rolling = pd.merge(fulldetail_faults['RecordID'],\n",
    "                                diagnostics_rolling,\n",
    "                                left_index= True,\n",
    "                                right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        # joining the two rolling windows\n",
    "        faults_diagnostics_rolling =  pd.merge(\n",
    "            diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            on = 'RecordID'\n",
    "        )\n",
    "\n",
    "    # this gets used if we only want to take into account the current diagnostics\n",
    "    # (essentially, NO rolling window for diagnostics)\n",
    "    else :\n",
    "\n",
    "        # simply get back 'RecordID' and other diagnostic columns\n",
    "        faults_diagnostics_rolling = pd.merge(\n",
    "            fulldetail_faults[['RecordID'] + diagnostics_cols].drop(columns=['EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            left_index= True,\n",
    "            right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "    predictor_train = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_train)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "    predictor_test = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_test)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "\n",
    "    return predictor_train, predictor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = windowize_predictors(faults_diagnostics, time_window='1d', faults_agg='max', windowize_diagnostics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0466            6.68m\n",
      "         2           0.0407            6.72m\n",
      "         3           0.0397            6.72m\n",
      "         4           0.0385            6.76m\n",
      "         5           0.0371            6.66m\n",
      "         6           0.0363            6.61m\n",
      "         7           0.0351            6.54m\n",
      "         8           0.0354            6.45m\n",
      "         9      281075.3210            6.36m\n",
      "        10 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            6.28m\n",
      "        20 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            5.57m\n",
      "        30 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            4.85m\n",
      "        40 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            4.15m\n",
      "        50 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            3.46m\n",
      "        60 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            2.76m\n",
      "        70 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            2.07m\n",
      "        80 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            1.39m\n",
      "        90 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000           41.65s\n",
      "       100 460581545762231603451447359907642942875092558098495588955744854732510395737689927105143199072518144.0000            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[440650    165]\n",
      " [  1018    968]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    440815\n",
      "           1       0.85      0.49      0.62      1986\n",
      "\n",
      "    accuracy                           1.00    442801\n",
      "   macro avg       0.93      0.74      0.81    442801\n",
      "weighted avg       1.00      1.00      1.00    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>spn_fmi_5394_17</td>\n",
       "      <td>0.302671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>spn_fmi_5246_0</td>\n",
       "      <td>0.106723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BarometricPressure</td>\n",
       "      <td>0.090633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistanceLtd</td>\n",
       "      <td>0.089737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>spn_fmi_4094_18</td>\n",
       "      <td>0.041880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>spn_fmi_5743_9</td>\n",
       "      <td>0.036837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>spn_fmi_524287_31</td>\n",
       "      <td>0.031526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.031323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>spn_fmi_5246_15</td>\n",
       "      <td>0.026365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>spn_fmi_5246_19</td>\n",
       "      <td>0.024093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EngineOilPressure</td>\n",
       "      <td>0.024056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>spn_fmi_1569_31</td>\n",
       "      <td>0.018177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EngineOilTemperature</td>\n",
       "      <td>0.014319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EngineTimeLtd</td>\n",
       "      <td>0.009470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>spn_fmi_4094_31</td>\n",
       "      <td>0.009114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>spn_fmi_3364_9</td>\n",
       "      <td>0.008980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FuelTemperature</td>\n",
       "      <td>0.008039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>spn_fmi_4360_19</td>\n",
       "      <td>0.007141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>spn_fmi_111_17</td>\n",
       "      <td>0.007130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>spn_fmi_3362_31</td>\n",
       "      <td>0.005616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 variable  importance\n",
       "638       spn_fmi_5394_17    0.302671\n",
       "624        spn_fmi_5246_0    0.106723\n",
       "2      BarometricPressure    0.090633\n",
       "4             DistanceLtd    0.089737\n",
       "467       spn_fmi_4094_18    0.041880\n",
       "699        spn_fmi_5743_9    0.036837\n",
       "622     spn_fmi_524287_31    0.031526\n",
       "16             LampStatus    0.031323\n",
       "626       spn_fmi_5246_15    0.026365\n",
       "628       spn_fmi_5246_19    0.024093\n",
       "7       EngineOilPressure    0.024056\n",
       "163       spn_fmi_1569_31    0.018177\n",
       "8    EngineOilTemperature    0.014319\n",
       "10          EngineTimeLtd    0.009470\n",
       "468       spn_fmi_4094_31    0.009114\n",
       "400        spn_fmi_3364_9    0.008980\n",
       "14        FuelTemperature    0.008039\n",
       "522       spn_fmi_4360_19    0.007141\n",
       "90         spn_fmi_111_17    0.007130\n",
       "389       spn_fmi_3362_31    0.005616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "[[103372     53]\n",
      " [   338    110]]\n",
      "ROC AUC Score\n",
      "0.8614902534617908\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)\n",
    "\n",
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2506           16.93m\n",
      "         2           1.1392           16.80m\n",
      "         3           1.0465           16.55m\n",
      "         4           0.9684           16.40m\n",
      "         5           0.9021           16.26m\n",
      "         6           0.8452           16.11m\n",
      "         7           0.7963           15.91m\n",
      "         8           0.7536           15.80m\n",
      "         9           0.7169           15.68m\n",
      "        10           0.6828           15.49m\n",
      "        20           0.4851           13.73m\n",
      "        30           0.3954           11.56m\n",
      "        40           0.3517            9.70m\n",
      "        50           0.3224            7.99m\n",
      "        60           0.3001            6.34m\n",
      "        70           0.2804            4.72m\n",
      "        80           0.2656            3.13m\n",
      "        90           0.2531            1.56m\n",
      "       100           0.2434            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is going to re-fit from scratch, unless we set warm_start=True\n",
    "# also, simply add this line to all X_ variables if you want to exclude 5246 influencing the model:\n",
    "# .drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col])\n",
    "gbr.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[427160  13655]\n",
      " [   226   1760]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    440815\n",
      "           1       0.11      0.89      0.20      1986\n",
      "\n",
      "    accuracy                           0.97    442801\n",
      "   macro avg       0.56      0.93      0.59    442801\n",
      "weighted avg       1.00      0.97      0.98    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>spn_fmi_1569_31</td>\n",
       "      <td>0.445535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FuelTemperature</td>\n",
       "      <td>0.232952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.092798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activeTransitionCount</td>\n",
       "      <td>0.038311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>spn_fmi_3031_9</td>\n",
       "      <td>0.034083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>spn_fmi_5743_9</td>\n",
       "      <td>0.020157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CruiseControlSetSpeed</td>\n",
       "      <td>0.010563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>spn_fmi_5742_9</td>\n",
       "      <td>0.009019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EngineTimeLtd</td>\n",
       "      <td>0.008450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>spn_fmi_3362_31</td>\n",
       "      <td>0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>spn_fmi_5848_9</td>\n",
       "      <td>0.007444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>spn_fmi_5246_16</td>\n",
       "      <td>0.006167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>spn_fmi_3364_9</td>\n",
       "      <td>0.006067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>spn_fmi_1761_17</td>\n",
       "      <td>0.005536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>spn_fmi_5246_0</td>\n",
       "      <td>0.005223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>spn_fmi_5394_4</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistanceLtd</td>\n",
       "      <td>0.004588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FuelLtd</td>\n",
       "      <td>0.004461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>spn_fmi_3216_4</td>\n",
       "      <td>0.004395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>spn_fmi_1761_19</td>\n",
       "      <td>0.004164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable  importance\n",
       "163        spn_fmi_1569_31    0.445535\n",
       "14         FuelTemperature    0.232952\n",
       "16              LampStatus    0.092798\n",
       "0    activeTransitionCount    0.038311\n",
       "300         spn_fmi_3031_9    0.034083\n",
       "699         spn_fmi_5743_9    0.020157\n",
       "3    CruiseControlSetSpeed    0.010563\n",
       "694         spn_fmi_5742_9    0.009019\n",
       "10           EngineTimeLtd    0.008450\n",
       "389        spn_fmi_3362_31    0.007591\n",
       "717         spn_fmi_5848_9    0.007444\n",
       "627        spn_fmi_5246_16    0.006167\n",
       "400         spn_fmi_3364_9    0.006067\n",
       "212        spn_fmi_1761_17    0.005536\n",
       "624         spn_fmi_5246_0    0.005223\n",
       "640         spn_fmi_5394_4    0.005000\n",
       "4              DistanceLtd    0.004588\n",
       "12                 FuelLtd    0.004461\n",
       "321         spn_fmi_3216_4    0.004395\n",
       "214        spn_fmi_1761_19    0.004164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "confusion matrix\n",
      "[[100420   3005]\n",
      " [    82    366]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    103425\n",
      "           1       0.11      0.82      0.19       448\n",
      "\n",
      "    accuracy                           0.97    103873\n",
      "   macro avg       0.55      0.89      0.59    103873\n",
      "weighted avg       1.00      0.97      0.98    103873\n",
      "\n",
      "ROC AUC Score\n",
      "0.9565056955523326\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('classification report')\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gbr_model_10.joblib']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load model\n",
    "# gbr = load('../models/gbr_model_1.joblib') \n",
    "\n",
    "# to save model\n",
    "# dump(gbr, '../models/gbr_model_10.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides saving the models, I will construct a json file that describes how they were obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dump = {\n",
    "    'file_path' : '../models/gbr_model_10.joblib',\n",
    "    'targets' : 'any row where a derate (5246) happens in the next 24 hours',\n",
    "    'diagnostics_file' : 'used imputer to average data per truck and then simple mean to average any remaining nulls',\n",
    "    'train_test_split' : 'using trucks and assuring same ratio of derate and nonderate',\n",
    "    'windowize_predictors': {'dataframe': 'merged faults and diagnostics',\n",
    "                             'how far in the past to aggregate' : '1 day (default)',\n",
    "                             'how to aggregate the one-hot encoded spn_fmi': 'max (default)',\n",
    "                             'use rolling window on diagnostics?' : 'False ',\n",
    "                             'how to aggregate diagnostics data' : 'not applicable'},\n",
    "    'pipeline' : {'step 1': 'GradientBoostingClassifier (default values)'},\n",
    "    'rebalancing' : {'over or under fitting': 'used SMOTE(k_neighbors=5, random_state=42)',\n",
    "                     'variables used': 'all (including derate columns)'}\n",
    "\n",
    "}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_train, gbr.predict(X_train))\n",
    "\n",
    "to_dump['train_confusion_matrix'] = {'TP': int(tmp_matrix[0][0]),\n",
    "                                     'FP': int(tmp_matrix[0][1]),\n",
    "                                     'FN': int(tmp_matrix[1][0]),\n",
    "                                     'TN': int(tmp_matrix[1][1])}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_test, gbr.predict(X_test))\n",
    "\n",
    "to_dump['test_confusion_matrix'] = {'TP': int(tmp_matrix[0][0]),\n",
    "                                     'FP': int(tmp_matrix[0][1]),\n",
    "                                     'FN': int(tmp_matrix[1][0]),\n",
    "                                     'TN': int(tmp_matrix[1][1])}\n",
    "\n",
    "\n",
    "to_dump['test_rocaouc_score'] = roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances = importances.sort_values('importance', ascending = False).head(20)\n",
    "\n",
    "tmp_dict={}\n",
    "\n",
    "for index, row in importances.iterrows():\n",
    "    tmp_dict[row[\"variable\"]] = row['importance']\n",
    "\n",
    "to_dump['top20_fature_importances'] = tmp_dict\n",
    "\n",
    "\n",
    "json_object = json.dumps(to_dump, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/gbr_model_10.json', 'w') as outfile:\n",
    "#     outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
