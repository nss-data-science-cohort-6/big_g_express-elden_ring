{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big G Express - Data Exploration\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults = pd.read_pickle('../data/faults_filtered.pkl')\n",
    "y_derate = pd.read_pickle('../data/target_derate.pkl')\n",
    "y_75derate = pd.read_pickle('../data/target_75derate.pkl')\n",
    "diagnostics_imputed = pd.read_pickle('../data/diagnostics_imputed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is mostly NaNs, just 250 values or so\n",
    "diagnostics_imputed = diagnostics_imputed.drop(columns='ServiceDistance')\n",
    "\n",
    "# and this drops columns that are not useful for predictions\n",
    "faults = faults.drop(columns=['ESS_Id', 'active', 'eventDescription','ecuSoftwareVersion', 'ecuSerialNumber', \n",
    "    'ecuModel', 'ecuMake', 'ecuSource', 'MCTNumber', 'Latitude', 'Longitude', 'LocationTimeStamp'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember there are parts of columns (where a particular truck had no values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just a simple fill with mean..\n",
    "diagnostics_imputed['AcceleratorPedal'] = diagnostics_imputed['AcceleratorPedal'].fillna(value=diagnostics_imputed['AcceleratorPedal'].mean())\n",
    "diagnostics_imputed['CruiseControlSetSpeed'] = diagnostics_imputed['CruiseControlSetSpeed'].fillna(value=diagnostics_imputed['CruiseControlSetSpeed'].mean())\n",
    "diagnostics_imputed['EngineTimeLtd'] = diagnostics_imputed['EngineTimeLtd'].fillna(value=diagnostics_imputed['EngineTimeLtd'].mean())\n",
    "diagnostics_imputed['FuelLevel'] = diagnostics_imputed['FuelLevel'].fillna(value=diagnostics_imputed['FuelLevel'].mean())\n",
    "diagnostics_imputed['FuelTemperature'] = diagnostics_imputed['FuelTemperature'].fillna(value=diagnostics_imputed['FuelTemperature'].mean())\n",
    "diagnostics_imputed['SwitchedBatteryVoltage'] = diagnostics_imputed['SwitchedBatteryVoltage'].fillna(value=diagnostics_imputed['SwitchedBatteryVoltage'].mean())\n",
    "diagnostics_imputed['Throttle'] = diagnostics_imputed['Throttle'].fillna(value=diagnostics_imputed['Throttle'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this took 30 min and didn't stop ...\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer, KNNImputer\n",
    "# scaler = StandardScaler().fit(diagnostics_imputed)\n",
    "\n",
    "# knn_filled = scaler.inverse_transform(KNNImputer().fit_transform(scaler.transform(diagnostics_imputed)))\n",
    "\n",
    "# diagnostics_imputed = IterativeImputer().fit_transform(diagnostics_imputed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics['spn_fmi'] = ['_'.join(i) for i in zip(faults_diagnostics['spn'].astype(str), faults_diagnostics['fmi'].astype(str))]\n",
    "\n",
    "faults_diagnostics = pd.get_dummies(faults_diagnostics, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "faults_diagnostics = faults_diagnostics.sort_values(by=['EquipmentID', 'EventTimeStamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to obtain the one hot encoded columns since there are so many\n",
    "faults_cols = ['EventTimeStamp'] + [col for col in faults_diagnostics.columns if 'spn_fmi' in col] \n",
    "\n",
    "diagnostics_cols = ['EventTimeStamp', 'activeTransitionCount', 'AcceleratorPedal',\n",
    "         'BarometricPressure', 'CruiseControlSetSpeed', 'DistanceLtd',\n",
    "         'EngineCoolantTemperature', 'EngineLoad', 'EngineOilPressure', \n",
    "        'EngineOilTemperature', 'EngineRpm', 'EngineTimeLtd', 'FuelLevel', 'FuelLtd', \n",
    "        'FuelRate', 'FuelTemperature', 'IntakeManifoldTemperature', 'LampStatus',\n",
    "        'Speed', 'SwitchedBatteryVoltage', 'Throttle', 'TurboBoostPressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_rolling = (\n",
    "    faults_diagnostics\n",
    "    .groupby('EquipmentID')[faults_cols]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .max()\n",
    ")\n",
    "\n",
    "faults_rolling = faults_rolling.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics_rolling = (\n",
    "    faults_diagnostics\n",
    "    .groupby('EquipmentID')[diagnostics_cols]\n",
    "    .rolling(window = '1d', on = \"EventTimeStamp\")\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "diagnostics_rolling = diagnostics_rolling.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_rolling = pd.merge(faults_diagnostics['RecordID'], #[['RecordID'] + diagnostics_cols]\n",
    "                          faults_rolling,\n",
    "                          left_index= True,\n",
    "                          right_on = 'level_1').drop(columns='level_1')\n",
    "\n",
    "diagnostics_rolling = pd.merge(faults_diagnostics['RecordID'],\n",
    "                          diagnostics_rolling,\n",
    "                          left_index= True,\n",
    "                          right_on = 'level_1').drop(columns='level_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics_rolling =  pd.merge(diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            on = 'RecordID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics_rolling = faults_diagnostics_rolling.sort_values('RecordID').drop(columns='RecordID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faults_diagnostics_rolling = faults_rolling.drop(columns=['RecordID', 'EquipmentID', 'EventTimeStamp_x', 'EventTimeStamp_y'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stratify on target (with derate) and split based on trucks\n",
    "X_train, X_test, y_train, y_test = train_test_split(faults_diagnostics_rolling, y_derate.sort_values('RecordID')['target'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, gbr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, gbr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances.sort_values('importance', ascending = False).head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: during one of the trainings there was a particular spn-fmi code that got to the top, with importance of 0.8! It was the 46262 code and after inspecting, despite appearing only once in the dataset, since there are many events happening in a smlal timeframe around it, it got picked up as important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_smoted = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True))#n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")\n",
    "\n",
    "gbr_smoted.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = gbr_smoted.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, gbr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, gbr_smoted.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'variable': gbr_smoted.feature_names_in_,\n",
    "    'importance': gbr_smoted['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances.sort_values('importance', ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=gbr_smoted.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Train-Test split\n",
    "\n",
    "The above is a good start. However, there are trucks whose events end up mixed between both train and test split. Instead, we want to make sure that each individual truck only appears in one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(faults['EquipmentID'].nunique())\n",
    "print(faults.loc[faults['spn'] == 5246]['EquipmentID'].nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, get the two lists of trucks that had (or not) a full derate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trucks = faults['EquipmentID'].unique()\n",
    "derate_trucks = faults.loc[faults['spn'] == 5246]['EquipmentID'].unique()\n",
    "no_derate_trucks = all_trucks[np.isin(all_trucks, derate_trucks, invert=True)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, put those lists together, marking if a derate occured (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_df = pd.concat([\n",
    "            pd.DataFrame({'EquipmentID': derate_trucks, 'derate': 1}),\n",
    "            pd.DataFrame({'EquipmentID': no_derate_trucks, 'derate': 0}) \n",
    "            ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, use the train_test_split, by accounting for the proportion of 'derates' in both (using stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_train, trucks_test = train_test_split(trucks_df, stratify=trucks_df['derate'], train_size = 0.8, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was just to verify that the proportions of trucks with and without derate in two samples are equal\n",
    "# print(trucks_train['derate'].value_counts(normalize=True))\n",
    "# print(trucks_test['derate'].value_counts(normalize=True))\n",
    "\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])].shape[0])\n",
    "# print(faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use that information to split the diagnostics and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to extract this because the train dataset only has RecordID\n",
    "records_train = faults.loc[faults['EquipmentID'].isin(trucks_train['EquipmentID'])]['RecordID']\n",
    "records_test = faults.loc[faults['EquipmentID'].isin(trucks_test['EquipmentID'])]['RecordID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_derate.loc[y_derate['RecordID'].isin(records_train)].sort_values('RecordID').drop(columns='RecordID')['target']\n",
    "y_test = y_derate.loc[y_derate['RecordID'].isin(records_test)].sort_values('RecordID').drop(columns='RecordID')['target']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the y_train and y_test are sorted, time to do the same for the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_diagnostics = faults.merge(diagnostics_imputed, left_on='RecordID', right_on='FaultId', how='inner').drop(columns='FaultId')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next it depends on how these get prepared, so I'll build a function. It takes the faults + diagnostic con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowize_predictors(fulldetail_faults, time_window='1d', faults_agg='max', windowize_diagnostics = True, diagnostics_agg='mean'):\n",
    "\n",
    "    # pull out the diagnostics table columns for later\n",
    "    diagnostics_cols = [col for col in fulldetail_faults.columns if col not in ['RecordID', 'spn', 'fmi', 'EquipmentID']]\n",
    "\n",
    "    # create a combined spn_fmi column to make dummies out of\n",
    "    fulldetail_faults['spn_fmi'] = ['_'.join(i) for i in zip(fulldetail_faults['spn'].astype(str), fulldetail_faults['fmi'].astype(str))]\n",
    "\n",
    "    # make dummies (one hot encode)\n",
    "    fulldetail_faults = pd.get_dummies(fulldetail_faults, columns=['spn_fmi'], prefix='spn_fmi')\n",
    "\n",
    "    # make sure the dataframe is in the right order to be able to later re-assign RecordID to it\n",
    "    fulldetail_faults = fulldetail_faults.sort_values(by=['EquipmentID', 'EventTimeStamp'])\n",
    "\n",
    "    # pull out all the Faults table columns (now one hot encoded)\n",
    "    faults_cols = ['EventTimeStamp'] + [col for col in fulldetail_faults.columns if 'spn_fmi' in col] \n",
    "\n",
    "    # rolling window function over faults - by default just taking IF a code appears in a 24 hr past window\n",
    "    faults_rolling = (\n",
    "        fulldetail_faults\n",
    "            .groupby('EquipmentID')[faults_cols]\n",
    "            .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "            .agg(faults_agg)\n",
    "            .reset_index()\n",
    "    )\n",
    "    \n",
    "    # by default I also decided to apply the same rolling window for the diagnostics part\n",
    "    # (can be turned off by setting = False, it is quick to execute)\n",
    "    if windowize_diagnostics:\n",
    "\n",
    "        # rolling window over diagnostics, by default using mean\n",
    "        diagnostics_rolling = (\n",
    "            fulldetail_faults\n",
    "                .groupby('EquipmentID')[diagnostics_cols]\n",
    "                .rolling(window = time_window, on = \"EventTimeStamp\")\n",
    "                .agg(diagnostics_agg)\n",
    "                .reset_index()\n",
    "        )\n",
    "\n",
    "        # joining back the faults rw to the original dataframe to get the \"RecordID\" out\n",
    "        faults_rolling = pd.merge(fulldetail_faults['RecordID'],\n",
    "                            faults_rolling,\n",
    "                            left_index= True,\n",
    "                            right_on = 'level_1').drop(columns='level_1')\n",
    "\n",
    "        # joining back the diagnostics rw to the original dataframe to get the \"RecordID\" out\n",
    "        diagnostics_rolling = pd.merge(fulldetail_faults['RecordID'],\n",
    "                                diagnostics_rolling,\n",
    "                                left_index= True,\n",
    "                                right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "        # joining the two rolling windows\n",
    "        faults_diagnostics_rolling =  pd.merge(\n",
    "            diagnostics_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            on = 'RecordID'\n",
    "        )\n",
    "\n",
    "    # this gets used if we only want to take into account the current diagnostics\n",
    "    # (essentially, NO rolling window for diagnostics)\n",
    "    else :\n",
    "\n",
    "        # simply get back 'RecordID' and other diagnostic columns\n",
    "        faults_diagnostics_rolling = pd.merge(\n",
    "            fulldetail_faults[['RecordID'] + diagnostics_cols].drop(columns=['EventTimeStamp']),\n",
    "            faults_rolling.drop(columns=['EquipmentID', 'EventTimeStamp']),\n",
    "            left_index= True,\n",
    "            right_on = 'level_1').drop(columns='level_1')\n",
    "        \n",
    "    predictor_train = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_train)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "    predictor_test = (\n",
    "        faults_diagnostics_rolling\n",
    "        .loc[faults_diagnostics_rolling['RecordID']\n",
    "             .isin(records_test)]\n",
    "        .sort_values('RecordID')\n",
    "        .drop(columns='RecordID')\n",
    "    )\n",
    "\n",
    "    return predictor_train, predictor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = windowize_predictors(faults_diagnostics, faults_agg='max', windowize_diagnostics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = Pipeline(\n",
    "    steps = [\n",
    "        ('gb', GradientBoostingClassifier(verbose=True)) #n_estimators = 1000, learning_rate=0.01\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0356            5.91m\n",
      "         2          58.2718            5.83m\n",
      "         3          58.0812            5.76m\n",
      "         4      572199.7808            5.76m\n",
      "         5      572199.7804            5.70m\n",
      "         6      572199.7802            5.74m\n",
      "         7      572199.7800            5.70m\n",
      "         8      572199.7798            5.66m\n",
      "         9      572199.7796            5.58m\n",
      "        10      572199.7792            5.51m\n",
      "        20      572178.6941            4.85m\n",
      "        30      572178.6940            4.21m\n",
      "        40      572178.6940            3.59m\n",
      "        50      572178.6940            2.99m\n",
      "        60      572178.6940            2.38m\n",
      "        70      572178.6940            1.79m\n",
      "        80      572178.6940            1.19m\n",
      "        90      572178.6940           35.63s\n",
      "       100      572178.6940            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[441548    103]\n",
      " [   706    444]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    441651\n",
      "           1       0.81      0.39      0.52      1150\n",
      "\n",
      "    accuracy                           1.00    442801\n",
      "   macro avg       0.91      0.69      0.76    442801\n",
      "weighted avg       1.00      1.00      1.00    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>spn_fmi_74_14</td>\n",
       "      <td>0.226072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>spn_fmi_111_1</td>\n",
       "      <td>0.151975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>spn_fmi_1761_14</td>\n",
       "      <td>0.151471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>spn_fmi_5246_19</td>\n",
       "      <td>0.136818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>spn_fmi_5246_0</td>\n",
       "      <td>0.119588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FuelTemperature</td>\n",
       "      <td>0.100117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EngineOilPressure</td>\n",
       "      <td>0.048231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.014192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EngineOilTemperature</td>\n",
       "      <td>0.013579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>spn_fmi_5246_15</td>\n",
       "      <td>0.011775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>spn_fmi_1668_9</td>\n",
       "      <td>0.009596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TurboBoostPressure</td>\n",
       "      <td>0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>spn_fmi_5848_9</td>\n",
       "      <td>0.003858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>spn_fmi_5246_16</td>\n",
       "      <td>0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FuelRate</td>\n",
       "      <td>0.001186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FuelLtd</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>spn_fmi_1761_11</td>\n",
       "      <td>0.001044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EngineTimeLtd</td>\n",
       "      <td>0.000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>spn_fmi_3216_9</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistanceLtd</td>\n",
       "      <td>0.000692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 variable  importance\n",
       "840         spn_fmi_74_14    0.226072\n",
       "89          spn_fmi_111_1    0.151975\n",
       "211       spn_fmi_1761_14    0.151471\n",
       "628       spn_fmi_5246_19    0.136818\n",
       "624        spn_fmi_5246_0    0.119588\n",
       "14        FuelTemperature    0.100117\n",
       "7       EngineOilPressure    0.048231\n",
       "16             LampStatus    0.014192\n",
       "8    EngineOilTemperature    0.013579\n",
       "626       spn_fmi_5246_15    0.011775\n",
       "177        spn_fmi_1668_9    0.009596\n",
       "20     TurboBoostPressure    0.004096\n",
       "717        spn_fmi_5848_9    0.003858\n",
       "627       spn_fmi_5246_16    0.002266\n",
       "13               FuelRate    0.001186\n",
       "12                FuelLtd    0.001090\n",
       "209       spn_fmi_1761_11    0.001044\n",
       "10          EngineTimeLtd    0.000764\n",
       "322        spn_fmi_3216_9    0.000701\n",
       "4             DistanceLtd    0.000692"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "[[103617     17]\n",
      " [   143     96]]\n",
      "ROC AUC Score\n",
      "0.8259668338761863\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(k_neighbors=5, random_state=42)\n",
    "\n",
    "X_smote, y_smote = oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2288           15.21m\n",
      "         2           1.1001           14.92m\n",
      "         3           0.9932           14.76m\n",
      "         4           0.9034           14.61m\n",
      "         5           0.8274           14.50m\n",
      "         6           0.7624           14.33m\n",
      "         7           0.7020           14.11m\n",
      "         8           0.6535           13.98m\n",
      "         9           0.6077           13.79m\n",
      "        10           0.5718           13.67m\n",
      "        20           0.3528           12.14m\n",
      "        30           0.2689           10.66m\n",
      "        40           0.2277            9.17m\n",
      "        50           0.2032            7.65m\n",
      "        60           0.1866            6.12m\n",
      "        70           0.1756            4.59m\n",
      "        80           0.1671            3.06m\n",
      "        90           0.1601            1.53m\n",
      "       100           0.1548            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;gb&#x27;, GradientBoostingClassifier(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('gb', GradientBoostingClassifier(verbose=True))])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is going to re-fit from scratch, unless we set warm_start=True\n",
    "# also, simply add this line to all X_ variables if you want to exclude 5246 influencing the model:\n",
    "# .drop(columns=[col for col in X_smote.columns if 'spn_fmi_5246' in col])\n",
    "gbr.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[427793  13858]\n",
      " [    72   1078]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    441651\n",
      "           1       0.07      0.94      0.13      1150\n",
      "\n",
      "    accuracy                           0.97    442801\n",
      "   macro avg       0.54      0.95      0.56    442801\n",
      "weighted avg       1.00      0.97      0.98    442801\n",
      "\n",
      "\n",
      "\n",
      "Variable Importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LampStatus</td>\n",
       "      <td>0.394906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>FuelTemperature</td>\n",
       "      <td>0.246263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>spn_fmi_1569_31</td>\n",
       "      <td>0.197288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>activeTransitionCount</td>\n",
       "      <td>0.056153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>spn_fmi_111_17</td>\n",
       "      <td>0.017830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>spn_fmi_3031_9</td>\n",
       "      <td>0.012642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>spn_fmi_111_18</td>\n",
       "      <td>0.010198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>spn_fmi_1761_17</td>\n",
       "      <td>0.008556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CruiseControlSetSpeed</td>\n",
       "      <td>0.004840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>spn_fmi_5743_9</td>\n",
       "      <td>0.003279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>spn_fmi_5394_5</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>spn_fmi_3362_31</td>\n",
       "      <td>0.002539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>spn_fmi_4094_31</td>\n",
       "      <td>0.002420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>spn_fmi_1761_19</td>\n",
       "      <td>0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DistanceLtd</td>\n",
       "      <td>0.001985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EngineLoad</td>\n",
       "      <td>0.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>spn_fmi_3251_16</td>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>spn_fmi_111_3</td>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EngineOilPressure</td>\n",
       "      <td>0.001768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>spn_fmi_102_2</td>\n",
       "      <td>0.001736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable  importance\n",
       "16              LampStatus    0.394906\n",
       "14         FuelTemperature    0.246263\n",
       "163        spn_fmi_1569_31    0.197288\n",
       "0    activeTransitionCount    0.056153\n",
       "90          spn_fmi_111_17    0.017830\n",
       "300         spn_fmi_3031_9    0.012642\n",
       "91          spn_fmi_111_18    0.010198\n",
       "212        spn_fmi_1761_17    0.008556\n",
       "3    CruiseControlSetSpeed    0.004840\n",
       "694         spn_fmi_5743_9    0.003279\n",
       "636         spn_fmi_5394_5    0.002888\n",
       "389        spn_fmi_3362_31    0.002539\n",
       "468        spn_fmi_4094_31    0.002420\n",
       "214        spn_fmi_1761_19    0.002255\n",
       "4              DistanceLtd    0.001985\n",
       "6               EngineLoad    0.001961\n",
       "370        spn_fmi_3251_16    0.001857\n",
       "92           spn_fmi_111_3    0.001856\n",
       "7        EngineOilPressure    0.001768\n",
       "42           spn_fmi_102_2    0.001736"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST\n",
      "confusion matrix\n",
      "[[100535   3099]\n",
      " [    37    202]]\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    103634\n",
      "           1       0.06      0.85      0.11       239\n",
      "\n",
      "    accuracy                           0.97    103873\n",
      "   macro avg       0.53      0.91      0.55    103873\n",
      "weighted avg       1.00      0.97      0.98    103873\n",
      "\n",
      "ROC AUC Score\n",
      "0.981873305662194\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(classification_report(y_train, gbr.predict(X_train)))\n",
    "print('\\n')\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "print('Variable Importances:')\n",
    "display(importances.sort_values('importance', ascending = False).head(20))\n",
    "\n",
    "print('------ TEST')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test, gbr.predict(X_test)))\n",
    "print('classification report')\n",
    "print(classification_report(y_test, gbr.predict(X_test)))\n",
    "print('ROC AUC Score')\n",
    "print(roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gbr_model_5.joblib']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load model\n",
    "# gbr = load('../models/gbr_model_1.joblib') \n",
    "\n",
    "# to save model\n",
    "# dump(gbr, '../models/gbr_model_5.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides saving the models, I will construct a json file that describes how they were obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dump = {\n",
    "    'file_path' : '../models/gbr_model_5.joblib',\n",
    "    'targets' : 'any row where a derate (5246) happens in the next 6 hours',\n",
    "    'diagnostics_file' : 'used imputer to average data per truck and then simple mean to average any remaining nulls',\n",
    "    'train_test_split' : 'using trucks and assuring same ratio of derate and nonderate',\n",
    "    'windowize_predictors': {'dataframe': 'merged faults and diagnostics',\n",
    "                             'how far in the past to aggregate' : '1 day (default) ',\n",
    "                             'how to aggregate the one-hot encoded spn_fmi': 'max (default)',\n",
    "                             'use rolling window on diagnostics?' : 'False ',\n",
    "                             'how to aggregate diagnostics data' : 'not applicable'},\n",
    "    'pipeline' : {'step 1': 'GradientBoostingClassifier (default values)'},\n",
    "    'rebalancing' : {'over or under fitting': 'used SMOTE(k_neighbors=5, random_state=42)',\n",
    "                     'variables used': 'eliminated 5246 columns (derates), by using the .drop on X_train and X_test'}\n",
    "\n",
    "}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_train, gbr.predict(X_train))\n",
    "\n",
    "to_dump['train_confusion_matrix'] = {'TP': int(tmp_matrix[0][0]),\n",
    "                                     'FP': int(tmp_matrix[0][1]),\n",
    "                                     'FN': int(tmp_matrix[1][0]),\n",
    "                                     'TN': int(tmp_matrix[1][1])}\n",
    "\n",
    "tmp_matrix = confusion_matrix(y_test, gbr.predict(X_test))\n",
    "\n",
    "to_dump['test_confusion_matrix'] = {'TP': int(tmp_matrix[0][0]),\n",
    "                                     'FP': int(tmp_matrix[0][1]),\n",
    "                                     'FN': int(tmp_matrix[1][0]),\n",
    "                                     'TN': int(tmp_matrix[1][1])}\n",
    "\n",
    "\n",
    "to_dump['test_rocaouc_score'] = roc_auc_score(y_true=y_test, y_score=gbr.predict_proba(X_test)[:,1])\n",
    "\n",
    "importances = pd.DataFrame({\n",
    "    'variable': gbr.feature_names_in_,\n",
    "    'importance': gbr['gb'].feature_importances_\n",
    "})\n",
    "\n",
    "importances = importances.sort_values('importance', ascending = False).head(20)\n",
    "\n",
    "tmp_dict={}\n",
    "\n",
    "for index, row in importances.iterrows():\n",
    "    tmp_dict[row[\"variable\"]] = row['importance']\n",
    "\n",
    "to_dump['top20_fature_importances'] = tmp_dict\n",
    "\n",
    "\n",
    "json_object = json.dumps(to_dump, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../models/gbr_model_5.json', 'w') as outfile:\n",
    "#     outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
